---
title: "Modeling Framework"
format: html
editor: source
---
```{r}
library(tidyverse)
library(sf)
library(VGAM)
library(lubridate)
library(lme4)
library(spdep)
library(car)
library(corrplot)
library(paletteer)
library(caret)
library(pROC)
#library(glmmTMB)
library(viridis)
library(emmeans)
select <- dplyr::select
```

Read in clustered data
```{r}
cnty_clus_offices <- readRDS("data/cnty_clus_offices.rds")


cnty_clus_offices <- cnty_clus_offices |>
  drop_na(criminality, gender, age, region)


cnty_clus_offices$deported <- factor(cnty_clus_offices$deported, levels = c(0,1))

cnty_clus_offices$region <- factor(cnty_clus_offices$region)

cnty_clus_offices$cluster <- factor(cnty_clus_offices$cluster)

cnty_clus_offices$gender <- factor(cnty_clus_offices$gender)

cnty_clus_offices$criminality <- factor(cnty_clus_offices$criminality)

cnty_clus_offices$criminality <- relevel(cnty_clus_offices$criminality, ref = "3 Other Immigration Violator")

cnty_clus_offices$cluster <- relevel(cnty_clus_offices$cluster, ref = "43")


# split into Latin American / Non-Latin American citizenship
latin_am_regions = c("Central America", "Caribbean", "Mexico", "South America")

cnty_clus_offices <- cnty_clus_offices |>
  mutate(latin_cit = case_when(region == "Mexico" ~ 1,
                                  region == "South America" ~ 1,
                                  region == "Central America" | region == "Caribbean" ~ 1,
                                  !(region %in% latin_am_regions) ~ 0)) 



trump_enc <- cnty_clus_offices |>
  filter(trump == 1)

biden_enc <- cnty_clus_offices |>
  filter(trump == 0)

```

```{r}
count(cnty_clus_offices |> filter(cluster %in% c("25","106")), trump)

```
```{r}
trump_enc |>
  filter(cluster %in% c("25","106"))
```


### Check for multicollinearity
```{r}
numeric_vars <- cnty_clus_offices |>
  group_by(office) |>
  select(c(avg_p_blk, avg_p_asn , avg_p_his, avg_p_nc, avg_pop_sqm)) |>
  drop_na() |>
  st_drop_geometry()
```

None of correlations are above 0.8, so I can keep all variables in the model
```{r}
corr_mat <- cor(numeric_vars)
corrplot(corr_mat, type="upper", method="ellipse")
```
```{r}
corr_mat
```

## Basic logistic regression

### Trump
```{r}
#cnty_clus_offices$criminality <- factor(cnty_clus_offices$criminality)

log_reg_trump <-glm(deported ~ criminality + gender + age + latin_cit + avg_p_blk + avg_p_asn  + avg_p_his + avg_p_nc + avg_pop_sqm + tps, 
               family = binomial,
               data = trump_enc)

saveRDS(log_reg_trump , file="models/log_reg_trump.rds")
```

```{r}
#log_reg_trump <- readRDS("models/log_reg_trump.rds")
```

```{r}
summary(log_reg_trump)
```

### Biden
```{r}
log_reg_biden <-glm(deported ~ criminality + gender + age + latin_cit + avg_p_blk + avg_p_asn  + avg_p_his + avg_pop_sqm + tps, 
               family = binomial,
               data = biden_enc)

saveRDS(log_reg_biden , file="models/log_reg_biden.rds")

summary(log_reg_biden)
```
## Administration 
```{r}
log_reg_admin <-glm(deported ~ criminality + gender + age + latin_cit + avg_p_blk + avg_p_asn  + avg_p_his + avg_pop_sqm + tps + trump, 
               family = binomial,
               data = cnty_clus_offices)

saveRDS(log_reg_admin, "models/log_reg_admin")
summary(log_reg_admin)
```



### Moran's I on basic logistic regression
Trump
```{r}
trump_enc$log_resids <- log_reg_trump$residuals
```

At the alpha = 0.05 level, we reject the null hypothesis that the distribution of the average residuals across offices are spatially uncorrelated. We conclude that there is clustering behavior of the residuals. 
```{r}
offices_grouped <- trump_enc |>
  group_by(office) |>
  mutate(avg_log_resid = mean(log_resids)) |>
  slice(1) |>
  ungroup()

office_coords <- st_coordinates(offices_grouped)

w1 <- 1/as.matrix(st_distance(offices_grouped ,
                              offices_grouped))
w1[is.infinite(w1)] <- 0

attr(w1, "class") <- NULL

moran.test(offices_grouped$avg_log_resid, mat2listw(w1, style="W"))
```

Biden
```{r}
biden_enc$log_resids <- log_reg_biden$residuals
```

At the alpha = 0.05 level, we reject the null hypothesis that the distribution of the average residuals across offices are spatially uncorrelated. We conclude that there is clustering behavior of the residuals. 
```{r}
offices_grouped <- biden_enc |>
  group_by(office) |>
  mutate(avg_log_resid = mean(log_resids)) |>
  slice(1) |>
  ungroup()

office_coords <- st_coordinates(offices_grouped)

w1 <- 1/as.matrix(st_distance(offices_grouped ,
                              offices_grouped))
w1[is.infinite(w1)] <- 0

attr(w1, "class") <- NULL

moran.test(offices_grouped$avg_log_resid, mat2listw(w1, style="W"))
```



## Interacting criminality with cluster 
Cluster reference group: 167
```{r}
crim_trump <- glm(deported ~ criminality + cluster + criminality:cluster + gender + age + latin_cit + tps, 
               family = binomial,
               data = trump_enc)

saveRDS(crim_trump, file="models/crim_trump.rds")
```

```{r}
crim_trump<- readRDS("models/crim_trump.rds")
summary(crim_trump)
```


```{r}
crim_biden <- glm(deported ~ criminality + cluster + criminality:cluster + gender + age + latin_cit + tps, 
               family = binomial,
               data = biden_enc)

saveRDS(crim_biden, file="models/crim_biden.rds")
```

```{r}
crim_biden<- readRDS("models/crim_biden.rds")
summary(crim_biden)
```

### Moran's I on cluster:criminality model
```{r}
cnty_clus_offices$clstr_crim_resids <- cluster_reg_crim$residuals
```

At the alpha = 0.05 level, we fail to reject the null hypothesis that the distribution of the average residuals across offices are spatially uncorrelated. (yay!)
```{r}
offices_grouped <- cnty_clus_offices |>
  group_by(office) |>
  mutate(avg_clstr_crim_resid = mean(clstr_crim_resids)) |>
  slice(1) |>
  ungroup()

office_coords <- st_coordinates(offices_grouped)

w1 <- 1/as.matrix(st_distance(offices_grouped ,
                              offices_grouped))
w1[is.infinite(w1)] <- 0

attr(w1, "class") <- NULL

moran.test(offices_grouped$avg_clstr_crim_resid, mat2listw(w1, style="W"))
```


## Interaction LatinAmerica:cluster

```{r}
latin_trump <- glm(deported ~ criminality + cluster +latin_cit:cluster+ gender + age + latin_cit + tps, 
               family = binomial,
               data = trump_enc)

saveRDS(latin_trump, file="models/latin_trump.rds")
```

```{r}
latin_trump <- readRDS("models/latin_trump.rds")
summary(latin_trump)
```

```{r}
latin_biden <- glm(deported ~ criminality + cluster +latin_cit:cluster+ gender + age + latin_cit + tps, 
               family = binomial,
               data = biden_enc)

saveRDS(latin_biden, file="models/latin_biden.rds")
```

```{r}
latin_biden <- readRDS("models/latin_biden.rds")
summary(latin_biden)
```


## Interaction tps:cluster

```{r}
tps_trump <- glm(deported ~ criminality + cluster +tps:cluster+ gender + age + latin_cit + tps, 
               family = binomial,
               data = trump_enc)

saveRDS(tps_trump, file="models/tps_trump.rds")
```
```{r}
tps_trump <- readRDS("models/tps_trump.rds")
summary(tps_trump)
```




```{r}
tps_biden <- glm(deported ~ criminality + cluster +tps:cluster+ gender + age + latin_cit + tps, 
               family = binomial,
               data = biden_enc)

saveRDS(tps_biden, file="models/tps_biden.rds")
```

```{r}
tps_biden<- readRDS("models/tps_biden.rds")
summary(tps_biden)
```


## Extract coefficients from all models
```{r}
model_names <- c('crim_trump', 'crim_biden', 'latin_trump', 'latin_biden', 'tps_trump', 'tps_biden')
models <- mget(model_names)
key_vars <- c("criminality1 Convicted Criminal", "criminality1 Convicted Criminal", "latin_cit", "latin_cit", "tps", "tps")

coef_extraction <- function(model, key_var, data, model_name) {
  
  coefs <- summary(model)$coefficients
  rownames <- rownames(coefs)
  
  # main effect
  main_effect <- coefs[key_var, "Estimate"]
  
  # pattern for both orders
  int_pattern <- paste0("^cluster([0-9]+):", key_var, "$|^", key_var, ":cluster([0-9]+)$")
  
  # extract matching rows
  int_rows <- grep(int_pattern, rownames, value = TRUE)
  int_coefs <- coefs[int_rows, , drop = FALSE]
  
  # set non-significant to 0
  int_coefs[int_coefs[, "Pr(>|z|)"] > 0.05, "Estimate"] <- 0
  
  # extract cluster number regardless of order
  cluster_num <- ifelse(
    grepl(paste0("^cluster([0-9]+):", key_var, "$"), rownames(int_coefs)),
    sub(paste0("^cluster([0-9]+):", key_var, "$"), "\\1", rownames(int_coefs)),
    sub(paste0("^", key_var, ":cluster([0-9]+)$"), "\\1", rownames(int_coefs))
  )
  
  int_df <- data.frame(
    cluster = factor(cluster_num),
    clstr_int = int_coefs[, "Estimate"]
  )
  
  # get all unique clusters
  clusters <- unique(data$cluster)
  
  # combine with main effect
  interaction_df <- data.frame(cluster = clusters) %>%
    left_join(int_df, by = "cluster") %>%
    mutate(
      main_effect = main_effect,
      clstr_int = ifelse(is.na(clstr_int), 0, clstr_int),
      cluster_effect = main_effect + clstr_int
    )
  
  # rename columns
  interaction_df <- interaction_df %>%
    rename(
      !!paste0(model_name, "_main_effect") := main_effect,
      !!paste0(model_name, "_clstr_int") := clstr_int,
      !!paste0(model_name, "_cluster_eff") := cluster_effect
    )
  
  return(interaction_df)
}
```

```{r}
coef_df_list <- Map(
  coef_extraction,
  model      = models,
  key_var    = key_vars,
  model_name = model_names,
  MoreArgs   = list(data =cnty_clus_offices)
)

coefs_df <- Reduce(
  left_join,
  coef_df_list
)
```
```{r}
coefs_df
```



```{r}
coefs_office_joined <- cnty_clus_offices |>
  group_by(office) |>
  slice(1) |>
  select(office, cluster, geom) |> 
  left_join(coefs_df, by="cluster")

head(coefs_office_joined)
```


### Transform interaction terms into percent change
```{r}
coefs_df_transf <- coefs_office_joined |>
  mutate(across(
    .cols = c(crim_trump_cluster_eff, crim_biden_cluster_eff, latin_trump_cluster_eff, latin_biden_cluster_eff, tps_trump_cluster_eff, tps_biden_cluster_eff),
    .fns = ~ (exp(.) - 1) * 100,
    .names = "{str_replace(.col, '_cluster_eff', '')}_pctdiff"
  )) |>
  select(c(office, cluster, crim_trump_pctdiff, crim_biden_pctdiff, latin_trump_pctdiff, latin_biden_pctdiff, tps_trump_pctdiff, tps_biden_pctdiff))

```

```{r}

coefs_df_transf |>
 filter(if_any(everything(), is.na)) |>
  distinct(cluster, .keep_all = TRUE)
```

```{r}
nrow(coefs_df_transf)
```



## Export coefficients

```{r}
saveRDS(coefs_df_transf, file = "mapping_coefs_admin.rds") 
saveRDS(cnty_clus_offices, file = "cnty_clus_offices.rds") 
```


```{r}
st_write(coefs_df_transf, "data/mapping_coefs_admin.gpkg")
```


### AIC model comparision
The model interacting cluster with criminality status has the lowest AIC
```{r}
print(AIC(crim_trump))
print(AIC(latin_trump))
print(AIC(tps_trump))
```

```{r}
print(AIC(crim_biden))
print(AIC(latin_biden))
print(AIC(tps_biden))
```


## Get predicted probabilities of deportation from cluster:criminality regression model
```{r}
pred_odds <- exp(predict(cluster_reg_crim))
pred_probs <- pred_odds / (pred_odds + 1)

cnty_clus_offices$pred_prob <- pred_probs
```

```{r}
cnty_clus_offices |>
  select(deported, pred_prob) |> 
  st_drop_geometry() |>
  slice_sample(n=10)
```


### Do train/test split to get confusion matrix, F1 score, and ROC curve
```{r}
set.seed(888)


# create train-test split, createDataPartition already shuffles your data
split_idx <- createDataPartition(cnty_clus_offices$deported, p = 0.8, list=FALSE)

encounters_train = cnty_clus_offices[split_idx, ]

encounters_test = cnty_clus_offices[-split_idx, ]



```

```{r}
cluster_reg_train <- glm(deported ~ criminality + cluster + criminality:cluster + gender + age + latin_cit + tps, 
               family = binomial,
               data = encounters_train)
```


```{r}
saveRDS(cluster_reg_train, file="models/cluster_reg_train.rds")
```

```{r}
#cluster_reg_train<- readRDS("cluster_reg_train.rds")
```


Get predictions from test set
```{r}
pred_probs <- predict(cluster_reg_train, newdata = encounters_test, type = "response")
```

ROC curve to decide where to place the "threshold" for classification
```{r}
roc_curve <- roc(response = encounters_test$deported, predictor = pred_probs)

plot(roc_curve, main = "ROC Curve", print.auc=TRUE,
     xlim = c(0, 1))
auc(roc_curve)
```


```{r}
# convert probabilities to predicted class
# TODO: ask about this
pred_dep <- ifelse(pred_probs >= 0.50, "1", "0")
pred_dep <- factor(pred_dep, levels= levels(encounters_test$deported))

# create confusion matrix
confusionMatrix(
  data = pred_dep,
  reference = encounters_test$deported,
  positive = "1" # well, not actually "positive"
)

```
```{r}
# proportion of deport predictions that were actually correct 
precision <- posPredValue(pred_dep, encounters_test$deported, positive = "1")

# proportion of correctly predicted deported cases
recall <- sensitivity(pred_dep, encounters_test$deported, positive = "1")

f1 <- (2*precision * recall) / (precision + recall)

print(precision)
print(recall)
print(f1)
```


```{r}
hist(pred_probs)
```


# GWR with aggregated offices
My computer crashes every time I try to compute the distance matrix because there are so many observations. So, my plan is to aggregate the data by office, but assign weights to offices with more datapoints. 

```{r}
# aggregate by offices
office_agg <- cnty_clus_offices |>
  group_by(office) |>
  reframe(prop_latin_cit = mean(latin_cit == 1),
         prop_crim_or_pending = mean(criminality == "1 Convicted Criminal" | criminality == "2 Pending Criminal Charges"),
         prop_female = mean(gender == "Female"),
         prop_male = mean(gender == "Male"),
         avg_prop_asn = mean(avg_p_asn),
         avg_prop_his = mean(avg_p_his),
         avg_prop_blk = mean(avg_p_blk),
         avg_prop_nc = mean(avg_p_nc),
         avg_pop_sqm = mean(avg_pop_sqm),
         avg_age = mean(age), 
         prop_deported = mean(deported == 1),
         num_encounters = num_encounters,
         office = office,
         aor = aor,
         geom = st_union(geom)) |>
   distinct(office, .keep_all = TRUE)

office_agg_sf <- st_as_sf(
  office_agg,
  sf_column_name = "geom",
  crs = st_crs(cnty_clus_offices)  
)
```



Note: summary statistics won't really make sense here because of the unequal distribution of encounters per office (weighting would need to be done first)

```{r}
office_agg |>
  summarize(min(num_encounters),
            max(num_encounters),
            mean(num_encounters),
            median(num_encounters),
            sd(num_encounters))
```


```{r}
office_agg_sp <- as(office_agg_sf, "Spatial")

bw <- bw.gwr(prop_deported ~ prop_latin_cit + prop_crim_or_pending + prop_female,
             data = office_agg_sp,
             approach = "CV",
             kernel = "bisquare",
             adaptive=TRUE)
```

## Fit OLS
```{r}
# ols first
ols_fit <- lm(prop_deported ~ prop_latin_cit + prop_crim_or_pending + prop_female + num_encounters + avg_prop_blk + avg_prop_asn  + avg_prop_his + avg_prop_nc + avg_pop_sqm,
             data = office_agg)

summary(ols_fit)
```

### Moran's I
```{r}
office_agg_sp$lm_resids <- ols_fit$residuals
```

At the alpha = 0.05 level, we reject the null hypothesis that the distribution of the average residuals across offices are spatially uncorrelated. 
```{r}
office_agg_sf <- st_as_sf(office_agg_sp)
office_coords <- st_coordinates(office_agg_sf)


w1 <- 1/as.matrix(st_distance(office_agg_sf,
                              office_agg_sf))
w1[is.infinite(w1)] <- 0

attr(w1, "class") <- NULL

moran.test(office_agg_sp$lm_resids, mat2listw(w1, style="W"))
```

## GWR
```{r}
# replaced population density with number of encounters
gwr_fit <- gwr.basic(prop_deported ~ prop_crim_or_pending + prop_latin_cit + prop_female + num_encounters,
             data = office_agg_sp,
             bw = bw,
             kernel = "bisquare",
             adaptive=TRUE)

gwr_results <- st_as_sf(gwr_fit$SDF)
gwr_fit 
```



```{r}
# alpha* adjustment

#effective number of parameters
pe <- 27.33118 
n <- nrow(office_agg_sp)
p <- 4

alpha_star <- 0.05/(1+pe - pe/(n*p))
alpha_star
df <- n - p - 1
t_star <- qt(1-alpha_star, df = df)
t_star 
```


```{r}
# assign significance
gwr_results <- gwr_results |>
  mutate(sig_crim = ifelse(abs(prop_crim_or_pending_TV) > t_star, prop_crim_or_pending, 0),
         sig_latin_cit = ifelse(abs(prop_latin_cit_TV) > t_star, prop_latin_cit, 0),
         #sig_his = ifelse(abs(avg_prop_his_TV) > t_star,avg_prop_his, 0),
         #sig_asn = ifelse(abs(avg_prop_asn_TV) > t_star, avg_prop_asn, 0),
         sig_female = ifelse(abs(prop_female_TV)> t_star, prop_female, 0))

hist(gwr_results$sig_crim)
hist(gwr_results$sig_latin_cit)
#hist(gwr_results$sig_his)
#hist(gwr_results$sig_asn)
hist(gwr_results$sig_female)

```

```{r}
# basic plot
gwr_results <- st_transform(gwr_results, st_crs(cnty_clus_offices))

# plot local coefficients as quintiles
# criminality
q_criminal <- quantile(gwr_results$sig_crim,
                       probs = seq(0, 1, 0.1),
                       na.rm=TRUE)

gwr_results$coef_crim_q <- case_when(
  gwr_results$sig_crim == 0 ~ "Zero",
  TRUE ~ as.character(cut(gwr_results$sig_crim,
                          breaks = unique(q_criminal),
                          include.lowest = TRUE))
)

plot_crim <- ggplot(gwr_results) +
  geom_sf(aes(color = coef_crim_q), linewidth = 0.2) +
  scale_color_manual(
    values = c("Zero" = "gray50", 
               setNames(viridis(5, direction = -1), 
                       levels(cut(gwr_results$sig_crim, 
                                 breaks = unique(q_criminal), 
                                 include.lowest = TRUE)))),
    name = "Coefficient"
  ) +
  theme_bw(base_size = 12) + 
  ggtitle("Criminal/Pending Criminal Charges Coef. (quintiles)")

plot_crim

```


```{r}
# 100% significant: space maters
# being from central america
# criminality
q_latin_cit <- quantile(gwr_results$sig_latin_cit,
                       probs = seq(0, 1, 0.2),
                       na.rm=TRUE)

gwr_results$coef_latin_cit_q <- case_when(
  gwr_results$sig_latin_cit == 0 ~ "Zero",
  TRUE ~ as.character(cut(gwr_results$sig_latin_cit,
                          breaks = unique(q_latin_cit),
                          include.lowest = TRUE))
)

plot_latin_cit <- ggplot(gwr_results) +
  geom_sf(aes(color = coef_latin_cit_q), linewidth = 0.2) +
  scale_color_manual(
    values = c("Zero" = "gray50", 
               setNames(viridis(5, direction = -1), 
                       levels(cut(gwr_results$sig_latin_cit, 
                                 breaks = unique(q_latin_cit), 
                                 include.lowest = TRUE)))),
    name = "Coefficient"
  ) +
  theme_bw(base_size = 12) + 
  ggtitle("Citizenship from a Latin American Country Coef. (quintiles)")

plot_latin_cit

```


```{r}
q_female <- quantile(gwr_results$sig_female,
                       probs = seq(0, 1, 0.2),
                       na.rm=TRUE)

gwr_results$coef_female_q <- case_when(
  gwr_results$sig_female == 0 ~ "Zero",
  TRUE ~ as.character(cut(gwr_results$sig_female,
                          breaks = unique(q_female),
                          include.lowest = TRUE))
)

plot_prop_female<- ggplot(gwr_results) +
  geom_sf(aes(color = coef_female_q), linewidth = 0.2) +
  scale_color_manual(
    values = c("Zero" = "gray50", 
               setNames(viridis(5, direction = -1), 
                       levels(cut(gwr_results$sig_female, 
                                 breaks = unique(q_female), 
                                 include.lowest = TRUE)))),
    name = "Coefficient"
  ) +
  theme_bw(base_size= 12) + 
  theme_bw() 
  ggtitle("Proportion Female Coef. (quintiles)")

plot_prop_female
```
